{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision_Project-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6QiOJlbb8GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "1from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azCHWPCZcB72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tqdm\n",
        "import heapq\n",
        "import datetime\n",
        "import glob\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi8LAmWPcDAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PATH = '/content/drive/My Drive/UCF-CV_Project/Training_set/Training'\n",
        "TEST_PATH = '/content/drive/My Drive/UCF-CV_Project/Testing_set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU6LOfXPcPaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def data_generator():\n",
        "    for index, category in enumerate(os.listdir(TRAIN_PATH)):\n",
        "        os.mkdir(category)\n",
        "        category_path = os.path.join(TRAIN_PATH, category)\n",
        "        for video in os.listdir(category_path):\n",
        "            video_path = os.path.join(category_path, video)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            num = max(1, num_of_frames // 50)\n",
        "            frame_idx = 0\n",
        "            taken = 0\n",
        "            while(1):\n",
        "                ret, frame = cap.read()\n",
        "                if(ret == False):\n",
        "                  break\n",
        "                if frame_idx % num == 0:\n",
        "                    frame = frame[:, :, ::-1]\n",
        "                    img = tf.image.resize(frame, (299, 299))\n",
        "                    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "                    taken += 1\n",
        "                    yield img, video_path\n",
        "                if(taken == 50):\n",
        "                  break\n",
        "                frame_idx += 1\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(data_generator,\n",
        "             output_types=(tf.float32, tf.string),\n",
        "             output_shapes=((299, 299, 3), ()))\n",
        "\n",
        "dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "inception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
        "inception_v3_output = inception_v3.output\n",
        "pooling_output = tf.keras.layers.GlobalAveragePooling2D()(inception_v3_output)\n",
        "feature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)\n",
        "\n",
        "current_path = None\n",
        "\n",
        "all_features = []\n",
        "\n",
        "for img, batch_paths in tqdm.tqdm(dataset):\n",
        "    batch_features = feature_extraction_model(img)\n",
        "    batch_features = tf.reshape(batch_features, (batch_features.shape[0], -1))\n",
        "    \n",
        "    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n",
        "        if path != current_path and current_path is not None:\n",
        "\n",
        "            video = os.path.split(current_path.decode())[-1]\n",
        "            category = os.path.split(os.path.split(current_path.decode())[-2])[-1]\n",
        "            print(os.path.join(category, video))\n",
        "            np.save(os.path.join(category, video.replace('.mpg', '.npy') ), all_features)\n",
        "            print(len(all_features))\n",
        "            all_features = []\n",
        "\n",
        "        current_path = path\n",
        "        all_features.append(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiCuVqo9wqeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories_list = ['/content/Basketball', \n",
        "          '/content/Diving',\n",
        "          '/content/Jumping',\n",
        "          '/content/Tennis',\n",
        "          '/content/Walking']\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "df = pd.DataFrame(columns=['category', 'id', 'path'])\n",
        "\n",
        "for index, category_path in enumerate(categories_list):\n",
        "    for video in os.listdir(category_path):\n",
        "        video_path = os.path.join(category_path, video)\n",
        "        category = os.path.dirname(video_path).split(os.sep)[-1]    \n",
        "        df = df.append({'category':category,  'id': index, 'path': video_path}, ignore_index=True)\n",
        "\n",
        "trainfile = open('train.txt', 'w')\n",
        "testfile = open('test.txt', 'w')\n",
        "categories = df.category.unique()\n",
        "\n",
        "LABELS = categories\n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit(categories)\n",
        "print(encoder)\n",
        "print('Classes: {}'.format(len(encoder.classes_)))\n",
        "\n",
        "for idx in range(5):    \n",
        "    class_subset = df[df['category'] == categories[idx]]\n",
        "    train, test = train_test_split(class_subset, test_size=0.2)    \n",
        "\n",
        "    for index, row in train.iterrows():\n",
        "        print(index, row)\n",
        "        trainfile.write(row['path'] + ' ' + str(row['id']) + '\\n')\n",
        "        \n",
        "    for index, row in test.iterrows():\n",
        "        testfile.write(row['path'] + '\\n')        \n",
        "trainfile.close()\n",
        "testfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NASZFZCA4-Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file = os.path.join('content', 'test.txt')\n",
        "train_file = os.path.join('content', 'train.txt')\n",
        "\n",
        "with open('/content/test.txt') as f:\n",
        "    test_list = [row.strip() for row in list(f)]\n",
        "\n",
        "with open('/content/train.txt') as f:\n",
        "    train_list = [row.strip() for row in list(f)]\n",
        "    train_list = [row.split(' ')[0] for row in train_list]\n",
        "\n",
        "def make_generator(file_list):\n",
        "    def generator():\n",
        "        np.random.shuffle(file_list)\n",
        "        for path in file_list:\n",
        "            full_path = path\n",
        "            #print(full_path [-4:])\n",
        "            if(full_path [-4:] != '.npy'):full_path += '.npy'\n",
        "            #print('hi', full_path)\n",
        "\n",
        "            label = os.path.basename(os.path.dirname(path))\n",
        "            features = np.load(full_path)\n",
        "\n",
        "            padded_sequence = np.zeros((50, 2048))\n",
        "            padded_sequence[0:len(features)] = np.array(features)\n",
        "\n",
        "            transformed_label = encoder.transform([label])\n",
        "            yield padded_sequence, transformed_label[0]\n",
        "    return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFRpUn_j439e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Masking(mask_value=0.),\n",
        "    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy', 'top_k_categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boEckVw_5Pgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\n",
        "                 output_types=(tf.float32, tf.int16),\n",
        "                 output_shapes=((50, 2048), (len(categories))))\n",
        "train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\n",
        "                 output_types=(tf.float32, tf.int16),\n",
        "                 output_shapes=((50, 2048), (len(categories))))\n",
        "valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnMDyGji6e9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import heapq\n",
        "import datetime\n",
        "import glob\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNY5tWWZ6ZSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, update_freq=1000, profile_batch=0)\n",
        "checkpoint = ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True)\n",
        "earlystopping = EarlyStopping(patience=10, verbose=1)\n",
        "model.fit(train_dataset, epochs=100, callbacks=[tensorboard_callback, checkpoint, earlystopping], validation_data=valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPy2UZKFMPe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, video in enumerate(os.listdir(TEST_PATH)):\n",
        "        video_path = os.path.join(TEST_PATH, video)\n",
        "        print(index, video_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17TmWW6-ME7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TEST_data_generator():\n",
        "    #os.mkdir('TEST')\n",
        "    for index, video in enumerate(os.listdir(TEST_PATH)):\n",
        "            video_path = os.path.join(TEST_PATH, video)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            num = max(1, num_of_frames // 50)\n",
        "            frame_idx = 0\n",
        "            taken = 0\n",
        "            while(1):\n",
        "                ret, frame = cap.read()\n",
        "                if(ret == False):\n",
        "                  break\n",
        "                if frame_idx % num == 0:\n",
        "                    frame = frame[:, :, ::-1]\n",
        "                    img = tf.image.resize(frame, (299, 299))\n",
        "                    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "                    taken += 1\n",
        "                    yield img, video_path\n",
        "                if(taken == 50):\n",
        "                  break\n",
        "                frame_idx += 1\n",
        "\n",
        "\n",
        "TEST_dataset = tf.data.Dataset.from_generator(TEST_data_generator,\n",
        "             output_types=(tf.float32, tf.string),\n",
        "             output_shapes=((299, 299, 3), ()))\n",
        "\n",
        "TEST_dataset = TEST_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "inception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
        "inception_v3_output = inception_v3.output\n",
        "pooling_output = tf.keras.layers.GlobalAveragePooling2D()(inception_v3_output)\n",
        "feature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)\n",
        "\n",
        "current_path = None\n",
        "\n",
        "all_features = []\n",
        "\n",
        "for img, batch_paths in TEST_dataset:\n",
        "    batch_features = feature_extraction_model(img)\n",
        "    batch_features = tf.reshape(batch_features, (batch_features.shape[0], -1))\n",
        "    \n",
        "    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n",
        "        if path != current_path and current_path is not None:\n",
        "            video = os.path.split(current_path.decode())[-1]\n",
        "            print(current_path)\n",
        "            np.save(os.path.join('TEST', video.replace('.mpg', '.npy') ), all_features)\n",
        "            all_features = []\n",
        "\n",
        "        current_path = path\n",
        "        all_features.append(features)\n",
        "\n",
        "video = os.path.split(current_path.decode())[-1]\n",
        "print(current_path)\n",
        "np.save(os.path.join('TEST', video.replace('.mpg', '.npy') ), all_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Har67oRNsso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_features(path):\n",
        "    features = np.load(path)\n",
        "    padded_sequence = np.zeros((50, 2048))\n",
        "    padded_sequence[0:len(features)] = np.array(features)\n",
        "    return np.array([padded_sequence])\n",
        "\n",
        "categories_mapping = {1: 0,\n",
        "                      3: 3,\n",
        "                      2: 1,\n",
        "                      4: 4,\n",
        "                      0: 2\n",
        "                      }\n",
        "\n",
        "videos = []\n",
        "labels = []\n",
        "i = 0\n",
        "for file in os.listdir('/content/TEST'):\n",
        "    i += 1\n",
        "    print(file)\n",
        "    file_path = os.path.join('/content/TEST', file)\n",
        "    features = load_features(file_path)\n",
        "    prediction = model.predict(features)\n",
        "    #print(np.argmax(prediction), categories_mapping[np.argmax(prediction)])\n",
        "    videos.append(file.replace('npy', 'mpg'))\n",
        "    labels.append(categories_mapping[np.argmax(prediction)])\n",
        "\n",
        "\n",
        "\n",
        "print(i)\n",
        "with open('submit.csv','w') as file:\n",
        "    file.write('Video,')\n",
        "    file.write('Label')\n",
        "    file.write('\\n')\n",
        "    for i in range(len(videos)):\n",
        "        file.write(videos[i] + ',')\n",
        "        file.write(str(labels[i]))\n",
        "        file.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}