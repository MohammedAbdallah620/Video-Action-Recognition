{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3DCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JIg7VET1Q_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9H0cXe-1SWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import np_utils, generic_utils\n",
        "\n",
        "import theano\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tqdm\n",
        "import heapq\n",
        "import datetime\n",
        "import glob\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "TRAIN_PATH = '/content/drive/My Drive/UCF-CV_Project/Training_set/Training'\n",
        "TEST_PATH = '/content/drive/My Drive/UCF-CV_Project/Testing_set'\n",
        "\n",
        "\n",
        "\n",
        "# image specification\n",
        "img_rows,img_cols,img_depth= 112,112, 40\n",
        "\n",
        "\n",
        "# Training data\n",
        "\n",
        "X_tr = []           # variable to store entire dataset\n",
        "\n",
        "\n",
        "label=[]\n",
        "\n",
        "for index, category in enumerate(os.listdir(TRAIN_PATH)):\n",
        "\n",
        "      print(index, category)\n",
        "      category_path = os.path.join(TRAIN_PATH, category)\n",
        "      for video in os.listdir(category_path):\n",
        "          video_path = os.path.join(category_path, video)\n",
        "          frames = []\n",
        "          cap = cv2.VideoCapture(video_path)\n",
        "          num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "          #ba5od el videos el 3adad el frames bt3etha akbar men 40\n",
        "          if(num_of_frames < 40):continue\n",
        "          #lw 3adad el frames kbar men 40 ba5od kol ad eh\n",
        "          num = max(1, num_of_frames // 40)\n",
        "          frame_idx = 0\n",
        "          taken = 0\n",
        "          while(1):\n",
        "              ret, frame = cap.read()\n",
        "              if(ret == False):\n",
        "                break\n",
        "              # Lw howa da el frame el el mfroud a5do fa ha5do\n",
        "              if frame_idx % num == 0:\n",
        "                  frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
        "                  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  frames.append(gray)\n",
        "                  taken += 1\n",
        "              if(taken == 40):\n",
        "                break\n",
        "              frame_idx += 1\n",
        "\n",
        "          cap.release()\n",
        "          cv2.destroyAllWindows()\n",
        "          input=np.array(frames)\n",
        "          X_tr.append(input)\n",
        "          label.append(index)\n",
        "      print(len(X_tr))\n",
        "lebel = np.array(label)\n",
        "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
        "num_samples = len(X_tr_array)\n",
        "\n",
        "print(num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cenm9lboq4xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40fY604EQyqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatination , column gamb column\n",
        "train_data = [X_tr_array,label]\n",
        "\n",
        "(X_train, y_train) = (train_data[0],train_data[1])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "#3ashan el gray scale maloush channel fana zawedtelo channel we ratebt el dimensions \n",
        "X_train = np.expand_dims(X_train, axis = 0)\n",
        "print('X_Train shape:', X_train.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train = X_train.transpose((1 , 3, 4 , 2, 0))\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzcmTnt864ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "088cd845-4fad-438c-b463-0e10d86b720a"
      },
      "source": [
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "patch_size = 40    # img_depth or number of frames used for each video\n",
        "\n",
        "print(X_train.shape, 'train samples')\n",
        "\n",
        "# CNN Training parameters\n",
        "#bad5al 8 videos 3ala el network\n",
        "batch_size = 8\n",
        "nb_classes = 5\n",
        "nb_epoch = 100\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "\n",
        "\n",
        "# Pre-processing\n",
        "X_train = X_train.astype('float32')\n",
        "X_train -= np.mean(X_train)\n",
        "X_train /=np.max(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(478, 112, 112, 40, 1)\n",
            "(478, 112, 112, 40, 1) train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4CBYcuj6VKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa75deb5-87e8-4aee-fae7-51cc4cffbc16"
      },
      "source": [
        "X_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 112, 40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ocfttgBMIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "# 64 filters, b3den size el filter , el video el da5el \n",
        "model.add(Convolution3D(64,3, 3, 3, input_shape=(img_rows, img_rows, 40, 1), activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, init='normal', activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nb_classes,init='normal'))\n",
        "\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='RMSprop')\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        " \n",
        "# Split the data\n",
        "\n",
        "X_train_new, X_val_new, y_train_new,y_val_new =  train_test_split(X_train, Y_train, test_size=0.2, random_state=4)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "earlystopping = EarlyStopping(patience=10, verbose=1)\n",
        "\n",
        "hist = model.fit(X_train_new, y_train_new, validation_data=(X_val_new,y_val_new),\n",
        "          batch_size=batch_size,nb_epoch = 200, callbacks=[earlystopping])\n",
        "\n",
        "\n",
        "\n",
        " # Evaluate the model\n",
        "score = model.evaluate(X_val_new, y_val_new, batch_size=batch_size)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85i5Hirt6s62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train_new, X_val_new, y_train_new,y_val_new =  train_test_split(X_train, Y_train, test_size=0.2, random_state=4)\n",
        "val_pred = []\n",
        "val_actural = []\n",
        "for video in X_val_new:\n",
        "  print(video.shape)\n",
        "  video = np.expand_dims(video, axis=0)\n",
        "  pred = model.predict(video)\n",
        "  #bashouf tele3 anhy class feehom\n",
        "  val_pred.append(np.argmax(pred))\n",
        "\n",
        "for label in y_val_new:\n",
        "  print(label)\n",
        "  val_actural.append(np.argmax(label))\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "confusionMatrix = metrics.confusion_matrix(val_actural, val_pred)\n",
        "confusionMatrixDataFrame = pd.DataFrame(confusionMatrix, index = [\"Walking\", \"Tennis\", \"Jumping\" , \"Diving\", \"Basketball\"], columns = [\"Walking\", \"Tennis\", \"Jumping\" , \"Diving\", \"Basketball\"])\n",
        "plt.figure(figsize = (9, 9))\n",
        "sns.heatmap(confusionMatrixDataFrame, annot = True)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca6f39ThackO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "videos = []\n",
        "labels = []\n",
        "\n",
        "for video in os.listdir(TEST_PATH):\n",
        "    video_path = os.path.join(TEST_PATH, video)\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if(num_of_frames < 40):continue\n",
        "\n",
        "    num = max(1, num_of_frames // 40)\n",
        "    frame_idx = 0\n",
        "    taken = 0\n",
        "    while(1):\n",
        "        ret, frame = cap.read()\n",
        "        if(ret == False):\n",
        "          break\n",
        "        if frame_idx % num == 0:\n",
        "            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            frames.append(gray)\n",
        "            taken += 1\n",
        "        if(taken == 40):\n",
        "          break\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    input=np.array(frames)\n",
        "    input = np.expand_dims(input, axis=0)\n",
        "    print(input.shape)\n",
        "    input = input.transpose((2 , 3, 1, 0 ))\n",
        "    print(input.shape)\n",
        "    input = np.expand_dims(input, axis=0)\n",
        "\n",
        "    prediction = model.predict(input)\n",
        "    videos.append(video.replace('npy', 'mpg'))\n",
        "    labels.append(np.argmax(prediction))\n",
        "    print(video, np.argmax(prediction))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22AVmwWHcdOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories_mapping = {0: 4,\n",
        "                      1: 3,\n",
        "                      2: 1,\n",
        "                      3: 0,\n",
        "                      4: 2\n",
        "                      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZCRW7tIchE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('submit.csv','w') as file:\n",
        "    file.write('Video,')\n",
        "    file.write('Label')\n",
        "    file.write('\\n')\n",
        "    for i in range(len(videos)):\n",
        "        file.write(videos[i] + ',')\n",
        "        file.write(str(categories_mapping[labels[i]]))\n",
        "        file.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}